2019-11-11 14:02:53,023 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：0条
2019-11-11 14:03:11,361 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_1, 一共：0条
2019-11-11 14:03:22,006 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_0, 一共：0条
2019-11-11 14:03:32,533 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_1, 一共：0条
2019-11-11 14:03:49,376 - webcrawer service - INFO - 运行成功: taipingyangbaoxian_3_3_0, 一共：0条
2019-11-11 14:04:03,662 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai_3_4, 一共：0条
2019-11-11 14:04:13,469 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_0, 一共：0条
2019-11-11 14:04:24,057 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_1, 一共：0条
2019-11-11 14:04:39,148 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：0条
2019-11-11 14:05:06,235 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：0条
2019-11-11 14:07:47,768 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：6条
2019-11-11 14:08:56,360 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：2条
2019-11-11 14:09:26,705 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang_3_14, 一共：0条
2019-11-11 14:09:48,250 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_0, 一共：0条
2019-11-11 14:10:11,299 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_1, 一共：0条
2019-11-11 14:10:30,971 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_0, 一共：0条
2019-11-11 14:10:50,626 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_1, 一共：0条
2019-11-11 14:11:13,126 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_0, 一共：0条
2019-11-11 14:11:46,382 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_1, 一共：0条
2019-11-11 14:12:06,695 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_0, 一共：0条
2019-11-11 14:12:22,365 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_1, 一共：0条
2019-11-11 14:12:55,580 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang_3_20, 一共：0条
2019-11-11 14:13:34,719 - webcrawer service - INFO - 运行成功: anzhaocai_3_23, 一共：0条
2019-11-11 14:13:45,705 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_0, 一共：0条
2019-11-11 14:14:04,688 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_1, 一共：0条
2019-11-11 14:14:23,865 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_0, 一共：0条
2019-11-11 14:14:43,173 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_1, 一共：0条
2019-11-11 14:14:52,893 - webcrawer service - INFO - 运行成功: chongqingguojitouzizixunjituanyouxiangongsi_3_27, 一共：0条
2019-11-11 14:15:10,719 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_0, 一共：0条
2019-11-11 14:15:21,281 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_1, 一共：0条
2019-11-11 14:15:45,938 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin_3_29, 一共：0条
2019-11-11 14:16:01,313 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_0, 一共：0条
2019-11-11 14:16:22,109 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_1, 一共：0条
2019-11-11 14:16:38,252 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang_3_32, 一共：0条
2019-11-11 14:22:59,429 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_0, 一共：1条
2019-11-11 14:23:26,726 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_1, 一共：0条
2019-11-11 14:29:45,643 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9, 一共：3条
2019-11-11 14:33:26,455 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_0, 一共：2条
2019-11-11 14:36:05,063 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_1, 一共：0条
2019-11-11 14:40:32,018 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_0, 一共：6条
2019-11-11 14:44:19,939 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_1, 一共：0条
2019-11-11 14:45:41,582 - webcrawer service - INFO - 运行成功: dalianshizhaobiaowang_3_13, 一共：0条
2019-11-11 14:48:01,892 - webcrawer service - INFO - 运行成功: shenzhenqinglima_3_21_0, 一共：1条
2019-11-11 14:48:53,526 - webcrawer service - INFO - 运行成功: shenzhenqinglima_3_21_1, 一共：0条
2019-11-11 14:49:02,923 - webcrawer service - INFO - 运行成功: chongqingguojitouzizixun_3_26, 一共：0条
2019-11-11 15:42:18,187 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：0条
2019-11-11 15:42:35,205 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_1, 一共：0条
2019-11-11 15:42:44,796 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_0, 一共：0条
2019-11-11 15:42:53,891 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_1, 一共：0条
2019-11-11 15:43:10,047 - webcrawer service - INFO - 运行成功: taipingyangbaoxian_3_3_0, 一共：0条
2019-11-11 15:44:11,125 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai_3_4, 一共：0条
2019-11-11 15:44:20,797 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_0, 一共：0条
2019-11-11 15:44:32,095 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_1, 一共：0条
2019-11-11 15:44:45,995 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：0条
2019-11-11 15:45:07,610 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：0条
2019-11-11 15:47:43,109 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：6条
2019-11-11 15:49:00,969 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：2条
2019-11-11 15:49:28,871 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang_3_14, 一共：0条
2019-11-11 15:49:55,359 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_0, 一共：0条
2019-11-11 15:50:16,031 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_1, 一共：0条
2019-11-11 15:50:45,735 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_0, 一共：0条
2019-11-11 15:51:13,375 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_1, 一共：0条
2019-11-11 15:51:41,543 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_0, 一共：0条
2019-11-11 15:52:03,050 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_1, 一共：0条
2019-11-11 15:52:22,283 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_0, 一共：0条
2019-11-11 15:52:41,767 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_1, 一共：0条
2019-11-11 15:53:08,891 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang_3_20, 一共：0条
2019-11-11 15:53:45,344 - webcrawer service - INFO - 运行成功: anzhaocai_3_23, 一共：0条
2019-11-11 15:53:57,130 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_0, 一共：0条
2019-11-11 15:54:18,486 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_1, 一共：0条
2019-11-11 15:54:31,262 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang_3_26_0
2019-11-11 15:54:31,372 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 126, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 156, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: 系统异常请联系管理员！
Message: unexpected alert open: {Alert text : 系统异常请联系管理员！}
  (Session info: chrome=76.0.3809.87)


2019-11-11 15:54:49,368 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_1, 一共：0条
2019-11-11 15:54:59,531 - webcrawer service - INFO - 运行成功: chongqingguojitouzizixunjituanyouxiangongsi_3_27, 一共：0条
2019-11-11 15:55:16,953 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_0, 一共：0条
2019-11-11 15:55:27,391 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_1, 一共：0条
2019-11-11 15:55:56,413 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin_3_29, 一共：0条
2019-11-11 15:56:10,157 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_0, 一共：0条
2019-11-11 15:56:30,303 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_1, 一共：0条
2019-11-11 15:56:45,966 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang_3_32, 一共：0条
2019-11-11 16:03:07,609 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_0, 一共：1条
2019-11-11 16:03:34,051 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_1, 一共：0条
2019-11-11 16:04:12,612 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9, 一共：0条
2019-11-11 16:13:17,223 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：0条
2019-11-11 16:15:20,594 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：0条
2019-11-11 16:15:38,391 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：0条
2019-11-11 16:19:49,751 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：6条
2019-11-11 16:21:12,777 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：2条
2019-11-11 16:23:10,643 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：0条
2019-11-11 16:23:30,564 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：0条
2019-11-11 16:26:33,657 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：6条
2019-11-11 16:27:57,281 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：2条
2019-11-11 16:30:19,062 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：0条
2019-11-11 16:30:35,765 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_1, 一共：0条
2019-11-11 16:30:44,854 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_0, 一共：0条
2019-11-11 16:30:53,734 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_1, 一共：0条
2019-11-11 16:31:09,859 - webcrawer service - INFO - 运行成功: taipingyangbaoxian_3_3_0, 一共：0条
2019-11-11 16:32:22,282 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai_3_4, 一共：0条
2019-11-11 16:32:31,937 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_0, 一共：0条
2019-11-11 16:32:41,265 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_1, 一共：0条
2019-11-11 16:32:52,563 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：0条
2019-11-11 16:33:08,937 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：0条
2019-11-11 16:36:02,189 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：6条
2019-11-11 16:37:59,750 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：2条
2019-11-11 16:38:29,454 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang_3_14, 一共：0条
2019-11-11 16:38:51,408 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_0, 一共：0条
2019-11-11 16:39:14,187 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_1, 一共：0条
2019-11-11 16:39:49,253 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_0, 一共：0条
2019-11-11 16:40:24,281 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_1, 一共：0条
2019-11-11 16:41:24,466 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_0, 一共：0条
2019-11-11 16:41:49,150 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_1, 一共：0条
2019-11-11 16:42:19,221 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_0, 一共：0条
2019-11-11 16:42:40,684 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_1, 一共：0条
2019-11-11 16:43:09,928 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang_3_20, 一共：0条
2019-11-11 16:43:46,604 - webcrawer service - INFO - 运行成功: anzhaocai_3_23, 一共：0条
2019-11-11 16:43:57,292 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_0, 一共：0条
2019-11-11 16:44:18,437 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_1, 一共：0条
2019-11-11 16:44:43,949 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_0, 一共：0条
2019-11-11 16:45:00,605 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_1, 一共：0条
2019-11-11 16:45:15,500 - webcrawer service - INFO - 运行成功: chongqingguojitouzizixunjituanyouxiangongsi_3_27, 一共：0条
2019-11-11 16:45:44,828 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_0, 一共：0条
2019-11-11 16:45:56,861 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_1, 一共：0条
2019-11-11 16:46:37,703 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin_3_29, 一共：0条
2019-11-11 16:46:54,355 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_0, 一共：0条
2019-11-11 16:47:14,549 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_1, 一共：0条
2019-11-11 16:47:30,405 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang_3_32, 一共：0条
2019-11-11 16:54:45,719 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_0, 一共：1条
2019-11-11 16:55:27,722 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_1, 一共：0条
2019-11-11 17:06:36,695 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9, 一共：3条
2019-11-11 17:12:24,845 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_0, 一共：2条
2019-11-11 17:16:08,922 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_1, 一共：0条
2019-11-11 17:24:25,705 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_0, 一共：6条
2019-11-11 17:24:40,243 - webcrawer service - ERROR - 运行失败: liaoningshengcaigouzhaobiaowang_3_12_1
2019-11-11 17:24:40,330 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 109, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 78, in model_log_in_web
    WebDriverWait(driver, 10, 0.5).until(EC.presence_of_element_located((By.ID, param["name"])))
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\wait.py", line 71, in until
    value = method(self._driver)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 64, in __call__
    return _find_element(driver, self.locator)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 415, in _find_element
    raise e
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 411, in _find_element
    return driver.find_element(*by)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: Unable to receive message from renderer
  (Session info: chrome=76.0.3809.87)


2019-11-11 17:30:28,718 - webcrawer service - INFO - 运行成功: dalianshizhaobiaowang_3_13, 一共：0条
2019-11-11 18:23:48,929 - webcrawer service - ERROR - 运行失败: shenzhenqinglima_3_21_0
2019-11-11 18:23:48,929 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 129, in RunMain
    self.getUrlList(model, parame, html_str, original_url,isloopBytime)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 22, in getUrlList
    ori_number = model.number_page(parame["number_xpath"], html_str)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 520, in number_page
    number = html_element.xpath(number_xpath)
AttributeError: 'NoneType' object has no attribute 'xpath'

2019-11-11 18:25:23,752 - webcrawer service - INFO - 运行成功: shenzhenqinglima_3_21_1, 一共：0条
2019-11-11 18:25:59,861 - webcrawer service - ERROR - 运行失败: chongqingguojitouzizixun_3_26
2019-11-11 18:25:59,861 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 106, in RunMain
    self.getUrlList(model, parame, html_str, original_url,isloopBytime)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 86, in getUrlList
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 156, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="Paging"]/div/div/table/tbody/tr/td[text()=6]"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 11:20:36,038 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 11:20:36,448 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 115, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 93, in model_log_in_web
    if login_info["params"]["captcha"] :
TypeError: list indices must be integers or slices, not str

2019-11-13 11:24:16,783 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 11:24:17,220 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 115, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 94, in model_log_in_web
    capt = utils.get_image_captcha()
TypeError: get_image_captcha() missing 1 required positional argument: 'self'

2019-11-13 13:44:58,733 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 13:44:59,166 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 98, in model_log_in_web
    capt = utils.get_image_captcha()
TypeError: get_image_captcha() missing 1 required positional argument: 'self'

2019-11-13 13:50:28,634 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 13:50:29,081 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 98, in model_log_in_web
    capt = get_image_captcha(driver)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in get_image_captcha
    top, bottom, left, right = get_position(driver)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 112, in get_position
    img = WebDriverWait(driver, 10, 0.5).wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'rzmimg')))
AttributeError: 'WebDriverWait' object has no attribute 'wait'

2019-11-13 13:53:31,464 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 13:53:32,211 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 98, in model_log_in_web
    capt = get_image_captcha(driver)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in get_image_captcha
    top, bottom, left, right = get_position(driver)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 112, in get_position
    img = WebDriverWait(driver, 10, 0.5).until(EC.presence_of_element_located((By.CLASS_NAME, 'rzmimg')))
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\wait.py", line 80, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 


2019-11-13 14:33:33,583 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 14:33:33,585 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 99, in model_log_in_web
    driver.find_element_by_id(login_info["params"]["captcha"]).send_keys(capt)
TypeError: list indices must be integers or slices, not str

2019-11-13 14:39:39,902 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 14:39:39,904 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 99, in model_log_in_web
    driver.find_element_by_id(login_info["captcha"]).send_keys(capt)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":"[id="topLoginRand"]"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 14:43:33,557 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 14:43:33,559 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 101, in model_log_in_web
    driver.find_element_by_xpath(login_info["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="loginErrForm"]/span[6]/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 14:52:27,171 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 14:52:27,172 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 158, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 101, in model_log_in_web
    driver.find_element_by_class(login_info["button"]).click()
AttributeError: 'WebDriver' object has no attribute 'find_element_by_class'

2019-11-13 14:59:36,495 - webcrawer service - INFO - 运行成功: ningxiazhaobiaowang_3_30_1, 一共：5条
2019-11-13 15:28:34,286 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 15:28:34,371 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 188, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 104, in model_log_in_web
    driver.find_element_by_class_name(captcha["name"]).send_keys(capt)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".yzm"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 15:32:39,446 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-13 15:32:39,448 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 188, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 115, in model_log_in_web
    driver.find_element_by_id(button["name"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":"[id="btn01"]"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 15:51:02,530 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 15:51:02,531 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 188, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 102, in model_log_in_web
    driver.find_element_by_id(captcha["name"]).send_keys(capt)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":"[id="yzm"]"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 15:55:43,398 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 15:55:43,400 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 188, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 117, in model_log_in_web
    driver.find_element_by_class_name(button["name"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":".btn01"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 16:07:56,037 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_1, 一共：81条
2019-11-13 16:31:03,555 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_1, 一共：81条
2019-11-13 16:43:30,114 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 16:43:30,117 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 190, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 125, in model_log_in_web
    driver.find_elemnt_by_xpath("/html/body/div[3]/div[1]/div[1]/div/input")
AttributeError: 'WebDriver' object has no attribute 'find_elemnt_by_xpath'

2019-11-13 16:56:59,355 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_1, 一共：81条
2019-11-13 16:59:13,414 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 16:59:13,494 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 190, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 83, in model_log_in_web
    WebDriverWait(driver, 10, 0.5).until(EC.presence_of_element_located((By.ID, param["name"])))
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\wait.py", line 71, in until
    value = method(self._driver)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 64, in __call__
    return _find_element(driver, self.locator)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 415, in _find_element
    raise e
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 411, in _find_element
    return driver.find_element(*by)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: chrome not reachable
  (Session info: chrome=76.0.3809.87)


2019-11-13 17:00:35,648 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 17:00:35,649 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 128, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 17:05:56,160 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 17:05:56,163 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 128, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 17:07:12,781 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 17:07:12,784 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 128, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 17:08:37,352 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 17:08:37,355 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 128, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-13 17:35:14,888 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-13 17:35:14,895 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 192, in log_in_web
    self.cookie_info = self.driver.get_cookies()                 # 列表中包含多个字典
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 841, in get_cookies
    return self.execute(Command.GET_ALL_COOKIES)['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: 验证码错误，请重新输入验证码。
Message: unexpected alert open: {Alert text : 验证码错误，请重新输入验证码。}
  (Session info: chrome=76.0.3809.87)


2019-11-14 09:23:46,713 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_1, 一共：0条
2019-11-14 09:30:51,367 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-14 09:30:51,464 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 145, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 95, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 186, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 83, in model_log_in_web
    WebDriverWait(driver, 10, 0.5).until(EC.presence_of_element_located((By.ID, param["name"])))
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\support\wait.py", line 80, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 


2019-11-14 11:01:32,480 - webcrawer service - ERROR - 运行失败: heilongjiangzhaobiaowang_3_10_0
2019-11-14 11:01:32,511 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 97, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 98, in model_log_in_web
    driver.find_element_by_xpath(login_info["verifyCodexpath"]).send_keys(res)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id='yzm']"}
  (Session info: chrome=76.0.3809.87)


2019-11-14 11:02:20,433 - webcrawer service - ERROR - 运行失败: heilongjiangzhaobiaowang_3_10_0
2019-11-14 11:02:20,433 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 97, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 98, in model_log_in_web
    driver.find_element_by_xpath(login_info["verifyCodexpath"]).send_keys(res)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id='yzm']"}
  (Session info: chrome=76.0.3809.87)


2019-11-14 11:07:52,354 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_0, 一共：0条
2019-11-14 11:10:20,167 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_0, 一共：0条
2019-11-14 11:14:20,432 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_0, 一共：0条
2019-11-14 11:18:37,275 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_0, 一共：23条
2019-11-14 11:25:47,747 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_1, 一共：11条
2019-11-14 11:37:01,766 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_0, 一共：36条
2019-11-14 11:39:13,344 - webcrawer service - ERROR - 运行失败: guangdongzhaobiaowang_3_17_1
2019-11-14 11:39:13,497 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 97, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 103, in model_log_in_web
    driver.find_element_by_xpath(login_info["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidArgumentException: Message: invalid argument: 'value' must be a string
  (Session info: chrome=76.0.3809.87)


2019-11-14 13:46:51,729 - webcrawer service - INFO - 运行成功: guangdongzhaobiaowang_3_17_1, 一共：104条
2019-11-14 13:49:52,790 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_0
2019-11-14 13:49:52,879 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 97, in RunMain
    driver = model.log_in_web(*login_infos)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 134, in log_in_web
    self.driver = model_log_in_web(self.driver, url, login_info,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 103, in model_log_in_web
    driver.find_element_by_xpath(login_info["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="loginErrForm"]/span[6]/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-14 13:55:04,220 - webcrawer service - INFO - 运行成功: ningxiazhaobiaowang_3_30_0, 一共：2条
2019-11-14 13:56:19,301 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-14 13:56:19,301 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 140, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 181, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-14 13:57:36,882 - webcrawer service - ERROR - 运行失败: ningxiazhaobiaowang_3_30_1
2019-11-14 13:57:36,898 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test_login.py", line 140, in RunMain
    html_str = model.parse_url("",url_type=parame["startPage"]["type"],url_params=parame["startPage"])
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 181, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"/html/body/div[3]/div[1]/div[1]/div/input"}
  (Session info: chrome=76.0.3809.87)


2019-11-14 14:00:28,282 - webcrawer service - INFO - 运行成功: ningxiazhaobiaowang_3_30_1, 一共：6条
2019-11-15 13:34:33,074 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：8条
2019-11-15 13:35:13,113 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_1, 一共：1条
2019-11-15 13:35:24,468 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_0, 一共：0条
2019-11-15 13:35:34,176 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_1, 一共：0条
2019-11-15 13:35:43,991 - webcrawer service - INFO - 运行成功: taipingyangbaoxian_3_3_0, 一共：0条
2019-11-15 13:39:06,158 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai_3_4, 一共：15条
2019-11-15 13:39:20,358 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_0, 一共：0条
2019-11-15 13:39:39,606 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_1, 一共：0条
2019-11-15 13:40:44,589 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：1条
2019-11-15 13:41:53,884 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：1条
2019-11-15 13:45:45,613 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：14条
2019-11-15 13:50:36,223 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：12条
2019-11-15 13:52:03,823 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang_3_14, 一共：3条
2019-11-15 13:52:26,016 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_0, 一共：0条
2019-11-15 13:52:41,700 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_1, 一共：0条
2019-11-15 13:54:06,761 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_0, 一共：7条
2019-11-15 13:55:29,561 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_1, 一共：9条
2019-11-15 13:56:07,158 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_0, 一共：0条
2019-11-15 13:56:38,476 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang_3_18_1, 一共：0条
2019-11-15 13:57:40,339 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_0, 一共：2条
2019-11-15 13:58:42,843 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai_3_19_1, 一共：1条
2019-11-15 13:59:07,850 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang_3_20, 一共：0条
2019-11-15 13:59:53,644 - webcrawer service - INFO - 运行成功: anzhaocai_3_23, 一共：0条
2019-11-15 14:00:16,224 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_0, 一共：0条
2019-11-15 14:00:39,626 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi_3_24_1, 一共：0条
2019-11-15 14:01:03,286 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_0, 一共：0条
2019-11-15 14:01:33,852 - webcrawer service - INFO - 运行成功: yunnanshengzhengfucaigouwang_3_26_1, 一共：0条
2019-11-15 14:01:48,447 - webcrawer service - INFO - 运行成功: chongqingguojitouzizixunjituanyouxiangongsi_3_27, 一共：0条
2019-11-15 14:02:06,914 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_0, 一共：0条
2019-11-15 14:02:25,141 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang_3_28_1, 一共：0条
2019-11-15 14:03:01,305 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin_3_29
2019-11-15 14:03:01,478 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 148, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key,vericode)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 106, in RunMain
    self.getUrlList(model, parame, html_str, original_url,isloopBytime)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 57, in getUrlList
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 181, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 80, in click
    self._execute(Command.CLICK_ELEMENT)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <a href="javascript:__doPostBack('ctl00$ContentPlaceHolder1$Pager','...')">4</a> is not clickable at point (522, 598). Other element would receive the click: <div id="UpdatePanel1">...</div>
  (Session info: chrome=76.0.3809.87)


2019-11-15 14:04:17,280 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_0, 一共：10条
2019-11-15 14:05:41,136 - webcrawer service - INFO - 运行成功: zhongguoyouzheng_3_31_1, 一共：16条
2019-11-15 14:06:26,075 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang_3_32, 一共：0条
2019-11-15 14:09:38,483 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_0, 一共：11条
2019-11-15 14:10:03,851 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_1, 一共：0条
2019-11-15 14:26:03,387 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9, 一共：85条
2019-11-15 14:34:40,588 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_0, 一共：34条
2019-11-15 14:42:06,137 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_1, 一共：37条
2019-11-15 14:54:23,872 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_0, 一共：41条
2019-11-15 15:31:47,410 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_0, 一共：8条
2019-11-15 15:32:25,221 - webcrawer service - INFO - 运行成功: zhongzhaoguojizhaobiaoyouxiangongsi_3_1_1, 一共：1条
2019-11-15 15:32:36,859 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_0, 一共：0条
2019-11-15 15:32:49,333 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi_3_2_1, 一共：0条
2019-11-15 15:33:04,529 - webcrawer service - INFO - 运行成功: taipingyangbaoxian_3_3_0, 一共：0条
2019-11-15 15:36:47,684 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai_3_4, 一共：15条
2019-11-15 15:37:01,808 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_0, 一共：0条
2019-11-15 15:37:17,573 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang_3_5_1, 一共：0条
2019-11-15 15:38:24,176 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_0, 一共：1条
2019-11-15 15:39:27,305 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_3_6_1, 一共：1条
2019-11-15 15:44:23,850 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_0, 一共：14条
2019-11-15 15:50:33,798 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai_shixian_3_6_1, 一共：12条
2019-11-15 15:55:16,809 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_0, 一共：11条
2019-11-15 15:55:44,458 - webcrawer service - INFO - 运行成功: huazhongzhaobiaowang_3_8_1, 一共：0条
2019-11-15 16:11:24,010 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9, 一共：68条
2019-11-15 16:15:43,223 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_0, 一共：20条
2019-11-15 16:16:37,736 - webcrawer service - INFO - 运行成功: heilongjiangzhaobiaowang_3_10_1, 一共：0条
2019-11-15 16:25:35,160 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_0, 一共：35条
2019-11-15 16:33:22,113 - webcrawer service - INFO - 运行成功: jilinshengcaigouzhaobiaowang_3_11_1, 一共：37条
2019-11-15 16:52:07,832 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_0, 一共：41条
2019-11-15 17:04:31,622 - webcrawer service - INFO - 运行成功: liaoningshengcaigouzhaobiaowang_3_12_1, 一共：39条
2019-11-15 17:05:06,888 - webcrawer service - INFO - 运行成功: dalianshizhaobiaowang_3_13, 一共：0条
2019-11-15 17:05:18,605 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang_3_14, 一共：0条
2019-11-15 17:05:35,681 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_0, 一共：0条
2019-11-15 17:05:50,462 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang_3_15_1, 一共：0条
2019-11-15 17:07:16,161 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_0, 一共：7条
2019-11-15 17:08:37,619 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang_3_16_1, 一共：9条
