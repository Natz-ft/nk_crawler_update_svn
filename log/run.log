2019-10-23 09:48:15,848 - webcrawer service - ERROR - 运行失败: shanxishenzhaobiaogonggongfuwupingtai
2019-10-23 09:48:16,066 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 09:48:21,473 - webcrawer service - ERROR - 运行失败: shanxishenzhaobiaogonggongfuwupingtai
2019-10-23 09:48:21,489 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 09:48:49,569 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 09:48:49,569 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 09:48:52,959 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 09:48:52,959 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:19:11,289 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:19:11,649 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:20:25,102 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:20:26,133 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:21:40,467 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:21:40,467 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:23:49,764 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:23:49,764 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:24:16,962 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:24:16,962 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:25:26,548 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:25:26,548 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 10:26:34,979 - webcrawer service - ERROR - 运行失败: shangdongcaigouyuzhaobiao
2019-10-23 10:26:34,979 - webcrawer service - ERROR - Traceback (most recent call last):
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\subprocess.py", line 1207, in _execute_child
    startupinfo)
  File "C:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\_pydev_bundle\pydev_monkey.py", line 452, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 98, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 14, in RunMain
    model = Crawler_URL()
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 33, in __init__
    self.driver = webdriver.Chrome(config.driver_windows, chrome_options=chrome_options)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 73, in __init__
    self.service.start()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home


2019-10-23 17:39:25,775 - webcrawer service - ERROR - 运行失败: neimengguzizhiquzhengfucaigou
2019-10-23 17:39:25,790 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 134, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-23 17:43:50,025 - webcrawer service - ERROR - 运行失败: neimengguzizhiquzhengfucaigou
2019-10-23 17:43:50,025 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 134, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-24 09:21:39,671 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:21:39,687 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 68, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 198, in page_url
    page_name["data"][page_name["pageNoKey"]]=cur_page_num
KeyError: 'pageNoKey'

2019-10-24 09:28:07,803 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:28:07,803 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 68, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 198, in page_url
    page_name["data"][page_name["pageNoKey"]]=cur_page_num
KeyError: 'pageNoKey'

2019-10-24 09:31:53,424 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:31:53,424 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 68, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 198, in page_url
    page_name["data"][page_name["pageNoKey"]]=cur_page_num
KeyError: 'pageNoKey'

2019-10-24 09:36:58,488 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:36:58,488 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 68, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 198, in page_url
    page_name["data"][page_name["pageNoKey"]]=cur_page_num
KeyError: 'pageNoKey'

2019-10-24 09:43:44,269 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:43:44,269 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 68, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 198, in page_url
    page_name["data"][page_name["pageNoKey"]]=cur_page_num
KeyError: 'pageNoKey'

2019-10-24 09:51:56,705 - webcrawer service - ERROR - 运行失败: tianjinshizhengfucaigoupingtai
2019-10-24 09:51:56,705 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 134, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-24 09:55:46,841 - webcrawer service - ERROR - 运行失败: guangxizhaobiaotoubiaogonggongfuwupingtai
2019-10-24 09:55:46,841 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 134, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-24 09:59:50,935 - webcrawer service - ERROR - 运行失败: guangxizhaobiaotoubiaogonggongfuwupingtai
2019-10-24 09:59:50,935 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 134, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-24 10:05:19,858 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai, 一共：1条
2019-10-24 10:35:54,777 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang, 一共：0条
2019-10-24 10:38:17,508 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang, 一共：1条
2019-10-24 10:57:13,156 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：0条
2019-10-24 10:58:31,960 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：4条
2019-10-24 13:24:35,582 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：6条
2019-10-24 13:34:30,025 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang, 一共：0条
2019-10-24 13:52:12,828 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang, 一共：0条
2019-10-24 14:39:55,412 - webcrawer service - ERROR - 运行失败: anzhaocai
2019-10-24 14:39:55,413 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 16, in RunMain
    parame = parameter[html_name]
KeyError: 'anzhaocai'

2019-10-24 14:46:41,008 - webcrawer service - INFO - 运行成功: anzhaocai, 一共：0条
2019-10-24 14:50:58,471 - webcrawer service - INFO - 运行成功: anzhaocai, 一共：0条
2019-10-24 14:54:44,694 - webcrawer service - INFO - 运行成功: anzhaocai, 一共：5条
2019-10-24 16:24:00,516 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi, 一共：0条
2019-10-24 16:25:06,555 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi, 一共：0条
2019-10-24 16:27:13,299 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi, 一共：0条
2019-10-24 16:33:42,050 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi, 一共：1条
2019-10-25 10:07:45,686 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-25 10:07:45,781 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 54, in parse_url
    html_str = self.driver.page_source
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:14:13,368 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-25 10:14:13,372 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 53, in parse_url
    self.driver.get(href_title)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:20:34,135 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-25 10:20:34,145 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 53, in parse_url
    self.driver.get(href_title)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:26:41,628 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-25 10:26:41,630 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 53, in parse_url
    self.driver.get(href_title)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:44:31,038 - webcrawer service - ERROR - 运行失败: zhongguoyouzheng
2019-10-25 10:44:31,044 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 53, in parse_url
    self.driver.get(href_title)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:48:51,472 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：4条
2019-10-25 10:51:22,017 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：4条
2019-10-25 10:52:44,907 - webcrawer service - ERROR - 运行失败: zhongguoyouzheng
2019-10-25 10:52:44,916 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 29, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 54, in parse_url
    html_str = self.driver.page_source
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=76.0.3809.87)


2019-10-25 10:55:00,757 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：4条
2019-10-25 11:33:55,640 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang, 一共：0条
2019-10-25 11:37:35,001 - webcrawer service - INFO - 运行成功: bingtuanzhengfucaigouwang, 一共：2条
2019-10-25 11:50:24,511 - webcrawer service - INFO - 运行成功: anzhaocai2, 一共：0条
2019-10-25 13:15:00,127 - webcrawer service - INFO - 运行成功: anzhaocai2, 一共：2条
2019-10-25 13:26:41,230 - webcrawer service - INFO - 运行成功: anzhaocai2, 一共：0条
2019-10-25 13:33:14,124 - webcrawer service - INFO - 运行成功: anzhaocai2, 一共：0条
2019-10-25 14:09:14,030 - webcrawer service - ERROR - 运行失败: anzhaocai2
2019-10-25 15:23:33,789 - webcrawer service - INFO - 运行成功: anzhaocai2, 一共：2条
2019-10-25 15:27:32,825 - webcrawer service - ERROR - 运行失败: anzhaocai2
2019-10-25 15:27:32,827 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 76, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 66, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: The result of the xpath expression "//*[@id="gridcontainer1"]/div/div[2]/div/a/text()" is: [object Text]. It should be an element.
  (Session info: chrome=76.0.3809.87)


2019-10-25 15:38:20,516 - webcrawer service - ERROR - 运行失败: anzhaocai2
2019-10-25 15:38:20,759 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 135, in Pipeline
    pd.DataFrame(self.time_change(result)).to_csv(csv, encoding='utf_8_sig')
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\generic.py", line 3228, in to_csv
    formatter.save()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\formats\csvs.py", line 183, in save
    compression=self.compression,
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\common.py", line 399, in _get_handle
    f = open(path_or_buf, mode, encoding=encoding, newline="")
PermissionError: [Errno 13] Permission denied: './data/anzhaocai2.csv'

2019-10-25 15:40:35,743 - webcrawer service - ERROR - 运行失败: anzhaocai2
2019-10-25 15:40:35,747 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 135, in Pipeline
    pd.DataFrame(self.time_change(result)).to_csv(csv, encoding='utf_8_sig')
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\generic.py", line 3228, in to_csv
    formatter.save()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\formats\csvs.py", line 183, in save
    compression=self.compression,
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\common.py", line 399, in _get_handle
    f = open(path_or_buf, mode, encoding=encoding, newline="")
PermissionError: [Errno 13] Permission denied: './data/anzhaocai2.csv'

2019-10-25 15:47:45,460 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-25 15:47:45,462 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 133, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 76, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 66, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="Pager"]/a[text()=11]"}
  (Session info: chrome=76.0.3809.87)


2019-10-28 09:41:22,420 - webcrawer service - ERROR - 运行失败: zhongguoyouzheng
2019-10-28 09:41:22,467 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 113, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-28 09:42:06,217 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：0条
2019-10-28 09:42:47,739 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：0条
2019-10-28 10:01:43,187 - webcrawer service - ERROR - 运行失败: shanghaigonggongziyuanjiaoyiwang
2019-10-28 10:01:43,713 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 141, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-28 10:29:02,007 - webcrawer service - ERROR - 运行失败: shanghaigonggongziyuanjiaoyiwang
2019-10-28 10:29:02,007 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 141, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-28 10:31:34,757 - webcrawer service - ERROR - 运行失败: shanghaigonggongziyuanjiaoyiwang
2019-10-28 10:31:34,757 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 141, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-28 11:15:07,209 - webcrawer service - ERROR - 运行失败: shanghaigonggongziyuanjiaoyiwang
2019-10-28 11:15:07,211 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 141, in Pipeline
    result = self.bank(result,text["type"])
KeyError: 'type'

2019-10-28 11:24:23,849 - webcrawer service - INFO - 运行成功: shanghaigonggongziyuanjiaoyiwang, 一共：1条
2019-10-28 11:26:47,716 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang, 一共：0条
2019-10-28 11:35:13,482 - webcrawer service - ERROR - 运行失败: hainanshenggonggongziyuanjiaoyiwang
2019-10-28 11:35:13,483 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-28 11:45:33,778 - webcrawer service - INFO - 运行成功: hainanshenggonggongziyuanjiaoyiwang, 一共：1条
2019-10-28 16:04:13,381 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin, 一共：0条
2019-10-29 09:27:31,667 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-29 09:27:31,797 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 30, in RunMain
    html_str = model.parse_url(original_url)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 77, in parse_url
    html_str = self.driver.page_source
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=76.0.3809.87)


2019-10-29 09:42:32,394 - webcrawer service - ERROR - 运行失败: chengdushigonggongziyuanjiaoyizhongxin
2019-10-29 09:42:32,398 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 97, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="Pager"]/a[text()=11]"}
  (Session info: chrome=76.0.3809.87)


2019-10-29 09:56:31,887 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：0条
2019-10-29 10:30:53,803 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang, 一共：0条
2019-10-29 10:41:52,010 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 10:41:52,012 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 97, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="searchMoreContent"]/a"}
  (Session info: chrome=76.0.3809.87)


2019-10-29 10:49:35,569 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang, 一共：1条
2019-10-29 10:54:02,466 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 10:54:02,482 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 10:57:27,555 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 10:57:28,494 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 11:11:27,438 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 11:11:27,439 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 11:37:43,084 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 11:37:43,668 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 11:38:24,200 - webcrawer service - ERROR - 运行失败: zhonggangzhaobiaoyouxianzerengongsi
2019-10-29 11:38:24,201 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 11:42:26,143 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 11:42:26,232 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 142, in Pipeline
    pd.DataFrame(self.time_change(result)).to_csv(csv, encoding='utf_8_sig')
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\generic.py", line 3228, in to_csv
    formatter.save()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\formats\csvs.py", line 183, in save
    compression=self.compression,
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\common.py", line 399, in _get_handle
    f = open(path_or_buf, mode, encoding=encoding, newline="")
PermissionError: [Errno 13] Permission denied: './data/xiamenshigongongziyuanjiaoyiwang.csv'

2019-10-29 11:44:03,865 - webcrawer service - ERROR - 运行失败: zhonggangzhaobiaoyouxianzerengongsi
2019-10-29 11:44:03,867 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 115, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 12:04:39,885 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 12:04:39,909 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 39, in RunMain
    ori_number = model.number_page(parame["number_xpath"], html_str)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 255, in number_page
    number = html_element.xpath(number_xpath)
AttributeError: 'NoneType' object has no attribute 'xpath'

2019-10-29 13:47:33,406 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang, 一共：1条
2019-10-29 13:51:52,754 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang
2019-10-29 13:51:52,758 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-29 13:57:50,761 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang, 一共：1条
2019-10-29 14:02:30,808 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi, 一共：0条
2019-10-29 14:04:33,741 - webcrawer service - ERROR - 运行失败: zhonggangzhaobiaoyouxianzerengongsi
2019-10-29 14:04:33,785 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 97, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: Unable to locate an element with the xpath expression /html/body/div[2]/div[2]/div[2]/div/div[5]/div[2]/div/ul/li[1]/a/@data-page-index=2 because of the following error:
TypeError: Failed to execute 'evaluate' on 'Document': The result is not a node set, and therefore cannot be converted to the desired type.
  (Session info: chrome=76.0.3809.87)


2019-10-29 14:14:57,792 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi, 一共：1条
2019-10-29 14:25:57,983 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang, 一共：0条
2019-10-29 14:29:15,688 - webcrawer service - ERROR - 运行失败: neimengguzizhiqugonggongziyuanjiaoyiwang
2019-10-29 14:29:15,692 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 64, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in page_url
    next_url = page_name["style"].replace(page_name["replaceKey"],str(cur_page_num))
KeyError: 'replaceKey'

2019-10-29 14:32:25,610 - webcrawer service - ERROR - 运行失败: neimengguzizhiqugonggongziyuanjiaoyiwang
2019-10-29 14:32:25,610 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 64, in RunMain
    original_url = model.page_url(original_url, tmp_parame, i)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 238, in page_url
    next_url = page_name["style"].replace(page_name["replaceKey"],str(cur_page_num))
KeyError: 'replaceKey'

2019-10-29 14:36:47,829 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang, 一共：5条
2019-10-29 15:04:58,340 - webcrawer service - ERROR - 运行失败: taipingyangbaoxian
2019-10-29 15:04:58,341 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 17, in RunMain
    parame = parameter[html_name]
KeyError: 'taipingyangbaoxian'

2019-10-29 15:06:08,888 - webcrawer service - INFO - 运行成功: taipingyangbaoxian, 一共：1条
2019-10-29 16:59:40,138 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-10-29 16:59:40,259 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 101, in parse_url
    self.driver.find_element_by_id(tmp_param["name"]).send_keys(tmp_param["value"])
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":"[id="dropdown-item dropdown-item-button"]"}
  (Session info: chrome=76.0.3809.87)


2019-10-29 17:00:20,585 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-10-29 17:00:20,588 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 101, in parse_url
    self.driver.find_element_by_id(tmp_param["name"]).send_keys(tmp_param["value"])
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=76.0.3809.87)


2019-10-29 17:06:48,417 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-10-29 17:06:48,783 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 101, in parse_url
    self.driver.find_element_by_id(tmp_param["name"]).send_keys(tmp_param["value"])
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 360, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"css selector","selector":"[id="dropdown-item dropdown-item-button"]"}
  (Session info: chrome=76.0.3809.87)


2019-10-29 17:12:48,634 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-10-29 17:12:48,637 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 105, in parse_url
    self.driver.find_elements_by_xpath(tmp_param["name"]).send_keys(tmp_param["value"])
AttributeError: 'list' object has no attribute 'send_keys'

2019-10-29 17:13:31,503 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-10-29 17:13:31,507 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 105, in parse_url
    self.driver.find_elements_by_xpath(tmp_param["name"]).send_keys(tmp_param["value"])
AttributeError: 'list' object has no attribute 'send_keys'

2019-10-30 09:50:59,402 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 09:57:26,990 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 10:03:32,521 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：1条
2019-10-30 10:30:54,035 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin, 一共：0条
2019-10-30 10:36:39,326 - webcrawer service - INFO - 运行成功: chengdushigonggongziyuanjiaoyizhongxin, 一共：9条
2019-10-30 10:39:44,377 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：0条
2019-10-30 10:50:06,193 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：0条
2019-10-30 10:50:58,988 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：0条
2019-10-30 13:52:13,717 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：9条
2019-10-30 13:52:29,247 - webcrawer service - ERROR - 运行失败: zhongguoyouzheng2
2019-10-30 13:52:29,384 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 13:54:29,888 - webcrawer service - INFO - 运行成功: zhongguoyouzheng, 一共：9条
2019-10-30 13:57:43,034 - webcrawer service - INFO - 运行成功: zhongguoyouzheng2, 一共：20条
2019-10-30 14:12:11,624 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 14:12:54,182 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang2, 一共：1条
2019-10-30 14:14:49,094 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 14:16:34,898 - webcrawer service - ERROR - 运行失败: lasagonggongziyuanjiaoyiwang2
2019-10-30 14:16:35,448 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 97, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="listCon"]/div/div/a[text()=2]"}
  (Session info: chrome=76.0.3809.87)


2019-10-30 14:20:49,202 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 14:27:35,413 - webcrawer service - ERROR - 运行失败: lasagonggongziyuanjiaoyiwang2
2019-10-30 14:27:36,032 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 97, in parse_url
    self.driver.find_element_by_xpath(url_param["button"]).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@id="listCon"]/div/div/a[text()=2]"}
  (Session info: chrome=76.0.3809.87)


2019-10-30 14:33:38,476 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 14:34:52,359 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang2, 一共：1条
2019-10-30 15:30:11,106 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang, 一共：0条
2019-10-30 15:30:58,063 - webcrawer service - INFO - 运行成功: lasagonggongziyuanjiaoyiwang2, 一共：1条
2019-10-30 16:14:22,427 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi, 一共：4条
2019-10-30 16:15:20,264 - webcrawer service - INFO - 运行成功: jiangxiguozhengzhaobiaoyouxiangongsi2, 一共：5条
2019-10-30 16:28:17,861 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai, 一共：7条
2019-10-30 16:31:05,118 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai, 一共：7条
2019-10-30 16:33:44,867 - webcrawer service - INFO - 运行成功: guangxizhaobiaotoubiaogonggongfuwupingtai2, 一共：18条
2019-10-30 16:37:28,374 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang, 一共：0条
2019-10-30 16:48:21,008 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 16:48:21,012 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 99, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: The result of the xpath expression "/" is: [object HTMLDocument]. It should be an element.
  (Session info: chrome=76.0.3809.87)


2019-10-30 16:50:39,642 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 16:50:39,644 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 16:55:42,665 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 16:55:43,058 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 99, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: The result of the xpath expression "/" is: [object HTMLDocument]. It should be an element.
  (Session info: chrome=76.0.3809.87)


2019-10-30 17:12:17,960 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 17:12:17,961 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 17:21:44,535 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 17:21:44,536 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 100, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: The result of the xpath expression "/" is: [object HTMLDocument]. It should be an element.
  (Session info: chrome=76.0.3809.87)


2019-10-30 17:24:48,155 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 17:24:48,156 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 17:25:15,424 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 17:25:15,425 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 17:48:19,992 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 17:48:19,993 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 17:55:34,263 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang2, 一共：0条
2019-10-30 17:58:57,286 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang2, 一共：0条
2019-10-30 18:00:56,565 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 18:00:56,567 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-30 18:01:47,795 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-30 18:01:47,796 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-31 10:05:52,576 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：3条
2019-10-31 10:27:20,023 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：5条
2019-10-31 10:36:00,296 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang2, 一共：6条
2019-10-31 10:47:48,120 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang, 一共：6条
2019-10-31 10:50:07,488 - webcrawer service - INFO - 运行成功: jiangsuzhengfucaigouwang2, 一共：7条
2019-10-31 10:54:00,060 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang, 一共：1条
2019-10-31 10:56:51,669 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang2, 一共：0条
2019-10-31 11:04:14,915 - webcrawer service - INFO - 运行成功: zhejiangshenggonggongziyuanjiaoyiwang, 一共：1条
2019-10-31 11:04:52,664 - webcrawer service - ERROR - 运行失败: zhejiangshenggonggongziyuanjiaoyiwang2
2019-10-31 11:04:52,753 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 142, in Pipeline
    pd.DataFrame(self.time_change(result)).to_csv(csv, encoding='utf_8_sig')
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\generic.py", line 3228, in to_csv
    formatter.save()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\formats\csvs.py", line 183, in save
    compression=self.compression,
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\common.py", line 399, in _get_handle
    f = open(path_or_buf, mode, encoding=encoding, newline="")
PermissionError: [Errno 13] Permission denied: './data/zhejiangshenggonggongziyuanjiaoyiwang2.csv'

2019-10-31 11:11:24,051 - webcrawer service - ERROR - 运行失败: zhejiangshenggonggongziyuanjiaoyiwang2
2019-10-31 11:11:24,054 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 142, in Pipeline
    pd.DataFrame(self.time_change(result)).to_csv(csv, encoding='utf_8_sig')
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\core\generic.py", line 3228, in to_csv
    formatter.save()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\formats\csvs.py", line 183, in save
    compression=self.compression,
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\pandas\io\common.py", line 399, in _get_handle
    f = open(path_or_buf, mode, encoding=encoding, newline="")
PermissionError: [Errno 13] Permission denied: './data/zhejiangshenggonggongziyuanjiaoyiwang2.csv'

2019-10-31 11:20:50,149 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：20条
2019-10-31 11:34:44,881 - webcrawer service - ERROR - 运行失败: shandongshengzhengfucaigouxinxigongkaipingtai2
2019-10-31 11:34:44,972 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-31 11:36:02,575 - webcrawer service - ERROR - 运行失败: shandongshengzhengfucaigouxinxigongkaipingtai2
2019-10-31 11:36:02,576 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-31 13:34:36,915 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai2, 一共：3条
2019-10-31 13:38:56,202 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai, 一共：20条
2019-10-31 13:40:06,669 - webcrawer service - INFO - 运行成功: shandongshengzhengfucaigouxinxigongkaipingtai2, 一共：0条
2019-10-31 13:45:07,780 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang, 一共：0条
2019-10-31 13:45:37,071 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang2, 一共：0条
2019-10-31 13:47:24,016 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang, 一共：5条
2019-10-31 13:47:51,093 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang2, 一共：0条
2019-10-31 13:48:55,995 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang2, 一共：0条
2019-10-31 13:58:11,622 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang2, 一共：1条
2019-10-31 13:59:25,174 - webcrawer service - INFO - 运行成功: neimengguzizhiqugonggongziyuanjiaoyiwang, 一共：5条
2019-10-31 14:05:48,861 - webcrawer service - INFO - 运行成功: tianjinshizhengfucaigoupingtai, 一共：9条
2019-10-31 14:11:01,908 - webcrawer service - ERROR - 运行失败: zhonggangzhaobiaoyouxianzerengongsi
2019-10-31 14:11:01,936 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 72, in RunMain
    html_str = model.parse_url("",url_type=original_url,url_params=tmp_parame)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 100, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: The result of the xpath expression "/" is: [object HTMLDocument]. It should be an element.
  (Session info: chrome=76.0.3809.87)


2019-10-31 14:11:11,417 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi2, 一共：0条
2019-10-31 14:38:52,519 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi, 一共：1条
2019-10-31 14:39:02,680 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi2, 一共：0条
2019-10-31 14:40:23,776 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi2, 一共：0条
2019-10-31 14:47:51,975 - webcrawer service - INFO - 运行成功: zhonggangzhaobiaoyouxianzerengongsi2, 一共：2条
2019-10-31 14:50:09,507 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 14:50:09,508 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-10-31 14:59:24,642 - webcrawer service - INFO - 运行成功: xiamenshigongongziyuanjiaoyiwang2, 一共：0条
2019-10-31 15:02:37,595 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 15:02:38,073 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 100, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//*[@onclick="clickMore(3)"]"}
  (Session info: chrome=76.0.3809.87)


2019-10-31 15:12:40,772 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 15:12:40,860 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 100, in parse_url
    self.driver.find_element_by_xpath(button).submit()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 85, in submit
    form = self.find_element(By.XPATH, "./ancestor-or-self::form")
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 659, in find_element
    {"using": by, "value": value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"./ancestor-or-self::form"}
  (Session info: chrome=76.0.3809.87)


2019-10-31 15:30:30,731 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 15:30:30,733 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 100, in parse_url
    self.driver.find_element_by_xpath(button).click()
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: invalid selector: Unable to locate an element with the xpath expression //*[@onclick="doSearch(this,"5")"] because of the following error:
SyntaxError: Failed to execute 'evaluate' on 'Document': The string '//*[@onclick="doSearch(this,"5")"]' is not a valid XPath expression.
  (Session info: chrome=76.0.3809.87)


2019-10-31 16:07:11,864 - webcrawer service - INFO - 运行成功: anzhaocai, 一共：2条
2019-10-31 16:09:40,493 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 16:09:40,494 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 104, in parse_url
    self.driver.find_element_by_xpath(button).send_keys(Keys.ENTER)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 479, in send_keys
    'value': keys_to_typing(value)})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable
  (Session info: chrome=76.0.3809.87)


2019-10-31 16:11:18,582 - webcrawer service - ERROR - 运行失败: xiamenshigongongziyuanjiaoyiwang2
2019-10-31 16:11:18,584 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 34, in RunMain
    html_str = model.parse_url("",url_type=url_info["type"],url_params=url_info)
  File "D:\crawler\Web_crawler\new_Crawler\CrawlerModule.py", line 104, in parse_url
    self.driver.find_element_by_xpath(button).send_keys(Keys.ENTER)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 479, in send_keys
    'value': keys_to_typing(value)})
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\yuele\AppData\Local\Programs\Python\Python37\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable
  (Session info: chrome=76.0.3809.87)


2019-11-01 09:41:25,052 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-11-01 09:41:25,068 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-11-01 09:41:54,435 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-11-01 09:41:54,440 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-11-01 10:15:12,008 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-11-01 10:15:12,022 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-11-01 10:43:07,330 - webcrawer service - ERROR - 运行失败: yunnanshengzhengfucaigouwang
2019-11-01 10:43:07,332 - webcrawer service - ERROR - Traceback (most recent call last):
  File "D:/crawler/Web_crawler/new_Crawler/try_pipeline_test.py", line 140, in Pipeline
    result = testClass.RunMain(text["original_url"], self.key_array, key)
  File "D:\crawler\Web_crawler\new_Crawler\test.py", line 40, in RunMain
    number = utils.retotalPage(ori_number)
  File "D:\crawler\Web_crawler\new_Crawler\utils.py", line 116, in retotalPage
    number = max(re.findall(r'\d+', ''.join(ori_number)))
ValueError: max() arg is an empty sequence

2019-11-01 16:03:14,925 - webcrawer service - INFO - 运行成功: jilinzhaobiao_1_11_0, 一共：0条
2019-11-01 16:04:55,230 - webcrawer service - INFO - 运行成功: jilinzhaobiao_1_11_0, 一共：0条
2019-11-01 16:17:35,647 - webcrawer service - INFO - 运行成功: jilinzhaobiao_1_11_0, 一共：0条
2019-11-04 14:05:58,700 - webcrawer service - INFO - 运行成功: hebeizhaobiaocaigouwang_3_9_0, 一共：0条
